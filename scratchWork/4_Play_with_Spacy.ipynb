{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business case:\n",
    "- Consulting Apple and Google on most loved things (product, service, app, etc) for them to invest in promotion of based on SXSW tweets\n",
    "\n",
    "**AVOID FALSE POSITIVE - MAXIMIZE PRECISION**\n",
    "- False Positive: a negative or neutral tweet is classified as positive and company invests in promoting something that customers view negatively\n",
    "    - False Positive is worse of the two because it leads to negative customer experience, lower NPS, and brand suffers in longer term. Basically spending money for customer to have negative experience.\n",
    "- False Negative: a positive tweet is classified as negative, and company misses opportunity to invest in promoting something that customers view positively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import re #regex\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Tweet preprocessor - Source: https://towardsdatascience.com/basic-tweet-preprocessing-in-python-efd8360d529e\n",
    "import preprocessor as p\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 896,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>No emotion toward brand or product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
       "      <td>Android</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Beautifully smart and simple idea RT @madebyma...</td>\n",
       "      <td>iPad or iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Counting down the days to #sxsw plus strong Ca...</td>\n",
       "      <td>Apple</td>\n",
       "      <td>Positive emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...   \n",
       "1  @jessedee Know about @fludapp ? Awesome iPad/i...   \n",
       "2  @swonderlin Can not wait for #iPad 2 also. The...   \n",
       "3  @sxsw I hope this year's festival isn't as cra...   \n",
       "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...   \n",
       "5  @teachntech00 New iPad Apps For #SpeechTherapy...   \n",
       "6                                                NaN   \n",
       "7  #SXSW is just starting, #CTIA is around the co...   \n",
       "8  Beautifully smart and simple idea RT @madebyma...   \n",
       "9  Counting down the days to #sxsw plus strong Ca...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1              iPad or iPhone App   \n",
       "2                            iPad   \n",
       "3              iPad or iPhone App   \n",
       "4                          Google   \n",
       "5                             NaN   \n",
       "6                             NaN   \n",
       "7                         Android   \n",
       "8              iPad or iPhone App   \n",
       "9                           Apple   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \n",
       "0                                   Negative emotion  \n",
       "1                                   Positive emotion  \n",
       "2                                   Positive emotion  \n",
       "3                                   Negative emotion  \n",
       "4                                   Positive emotion  \n",
       "5                 No emotion toward brand or product  \n",
       "6                 No emotion toward brand or product  \n",
       "7                                   Positive emotion  \n",
       "8                                   Positive emotion  \n",
       "9                                   Positive emotion  "
      ]
     },
     "execution_count": 896,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import file\n",
    "raw_data = pd.read_csv('../data/judge-1377884607_tweet_product_company.csv', encoding= 'unicode_escape')\n",
    "df = raw_data.copy()\n",
    "\n",
    "# Preview file \n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 897,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9093 entries, 0 to 9092\n",
      "Data columns (total 3 columns):\n",
      "tweet_text                                            9092 non-null object\n",
      "emotion_in_tweet_is_directed_at                       3291 non-null object\n",
      "is_there_an_emotion_directed_at_a_brand_or_product    9093 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 213.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Overview file\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill nulls\n",
    "df['emotion_in_tweet_is_directed_at'].fillna('None', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop row 6, tweet_text null row; 9092 row is foreign characters\n",
    "df.drop(labels=[6, 9092], axis=0, inplace=True)\n",
    "\n",
    "# reset index post drop\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 900,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No emotion toward brand or product    5387\n",
       "Positive emotion                      2978\n",
       "Negative emotion                       570\n",
       "I can't tell                           156\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 900,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts exploration\n",
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 901,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter down emotions to Neutral\n",
    "df['is_there_an_emotion_directed_at_a_brand_or_product'] = df['is_there_an_emotion_directed_at_a_brand_or_product'].map({\"No emotion toward brand or product\" : \"Neutral\",\n",
    "                                                                                                                         \"Positive emotion\": \"Positive\",\n",
    "                                                                                                                         \"Negative emotion\": \"Negative\",\n",
    "                                                                                                                         \"I can't tell\": \"Neutral\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 902,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral     5543\n",
       "Positive    2978\n",
       "Negative     570\n",
       "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
      ]
     },
     "execution_count": 902,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_there_an_emotion_directed_at_a_brand_or_product'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 903,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create target; Positive only - 32%\n",
    "df['target'] = df['is_there_an_emotion_directed_at_a_brand_or_product'].map({\"Positive\": 1,\n",
    "                                                                             \"Neutral\": 0,\n",
    "                                                                             \"Negative\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 904,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9091 entries, 0 to 9090\n",
      "Data columns (total 4 columns):\n",
      "tweet_text                                            9091 non-null object\n",
      "emotion_in_tweet_is_directed_at                       9091 non-null object\n",
      "is_there_an_emotion_directed_at_a_brand_or_product    9091 non-null object\n",
      "target                                                9091 non-null int64\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 284.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check work\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 905,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Createw new column for cleaned tweet text\n",
    "df['clean_tweet'] = df['tweet_text'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace hashtags, links, rts, and mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using placeholder(ph) because if use {hashtag}, \n",
    "# tokenizing will be wrong, separates first { then rest of string\n",
    "\n",
    "# Replace hashtags with placeholder(HASHPH)\n",
    "df['clean_tweet'] = df['clean_tweet'].replace({'#':'hashph'}, regex=True)\n",
    "\n",
    "# Replace links with placeholder(LINKPH)\n",
    "df['clean_tweet'] = df['clean_tweet'].replace({'http':'linkph',\n",
    "                                              '{link}':'linkph'}, regex=True)\n",
    "\n",
    "# Replace RT with placeholder(RTPH)\n",
    "df['clean_tweet'] = df['clean_tweet'].replace({'RT':'rtph'}, regex=True)\n",
    "# Did not account for rt (stand alone string)\n",
    "\n",
    "# Replace mentions with placeholder(MENPH)\n",
    "df['clean_tweet'] = df['clean_tweet'].replace({'@mention':'menph'}, regex=True)\n",
    "# Account for mentions that do not have '@mention' in the original text and have usernames\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: re.sub(r'@\\w+', 'menph', (x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 907,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9085"
      ]
     },
     "execution_count": 907,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['clean_tweet'].str.contains('hashph')])\n",
    "# Almost all contain hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4193"
      ]
     },
     "execution_count": 908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['clean_tweet'].str.contains('linkph')])\n",
    "# 51% contain links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 909,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2686"
      ]
     },
     "execution_count": 909,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['clean_tweet'].str.contains('rtph')])\n",
    "# 29% contain RTs (systematic, lowercase rts not accounted for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 910,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4193"
      ]
     },
     "execution_count": 910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['clean_tweet'].str.contains('linkph')])\n",
    "# 51% contain links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 911,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4918"
      ]
     },
     "execution_count": 911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df['clean_tweet'].str.contains('menph')])\n",
    "# 54% contain mentions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning html, removing punctuation, lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 912,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean 'clean_tweet' column of HTML; there were things like &quot\n",
    "html_ent_clean = re.compile('&.*?;')\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: re.sub(html_ent_clean, '',x))\n",
    "\n",
    "# Remove punctuation\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: re.sub(r'[^\\w\\s]', '', (x)))\n",
    "\n",
    "# Source: https://towardsdatascience.com/basic-tweet-preprocessing-in-python-efd8360d529e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 913,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       menph I have a 3G iPhone After 3 hrs tweeting ...\n",
       "1       menph Know about menph  Awesome iPadiPhone app...\n",
       "2       menph Can not wait for hashphiPad 2 also They ...\n",
       "3       menph I hope this years festival isnt as crash...\n",
       "4       menph great stuff on Fri hashphSXSW Marissa Ma...\n",
       "                              ...                        \n",
       "9086    menph Yup but I dont have a third app yet Im o...\n",
       "9087                    Ipad everywhere hashphSXSW linkph\n",
       "9088    Wave buzz rtph menph We interrupt your regular...\n",
       "9089    Googles Zeiger a physician never reported pote...\n",
       "9090    Some Verizon iPhone customers complained their...\n",
       "Name: clean_tweet, Length: 9091, dtype: object"
      ]
     },
     "execution_count": 913,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview clean text column, sanity check\n",
    "df['clean_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 914,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://www.dataquest.io/blog/tutorial-text-classification-in-python-using-spacy/\n",
    "# Create our list of stopwords\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove spacy stopwords\n",
    "df['clean_tweet'] = df['clean_tweet'].apply(lambda x: ' '.join(\n",
    "    [word for word in x.split() if word.lower() not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase text\n",
    "df['clean_tweet'] = df['clean_tweet'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new column for tokenized tweets\n",
    "df['token_tweet'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to tokenize with spacy\n",
    "\n",
    "def tokenize_tweet(tweet):\n",
    "    my_tweet = nlp(tweet) \n",
    "    token_list = []\n",
    "    for token in my_tweet:\n",
    "        token_list.append(token.text)\n",
    "    return token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create token tweet values\n",
    "df['token_tweet'] = df['clean_tweet'].apply(tokenize_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview new column\n",
    "df['token_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review df overview\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "def lemmatize_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(w) for w in text]\n",
    "\n",
    "df['token_tweet'] = df['token_tweet'].apply(lemmatize_text)\n",
    "\n",
    "# Rejoin in new column\n",
    "df['clean_token_tweet'] = df['token_tweet'].map(lambda x: ' '.join(x))\n",
    "\n",
    "# Source: https://stackoverflow.com/questions/59567357/lemmatize-tokenised-column-in-pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview new column \n",
    "df['clean_token_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review df\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Playing with SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x89ÛÏ@mention &quot;Apple has opened a pop-up store in Austin so the nerds in town for #SXSW can get their new iPads. {link} #wow'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_text'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       ".@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW."
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word tokenization\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = English()\n",
    "\n",
    "text = df['tweet_text'][0]\n",
    "\n",
    "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "my_doc = nlp(text)\n",
    "my_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.@wesley83', 'I', 'have', 'a', '3', 'G', 'iPhone', '.', 'After', '3', 'hrs', 'tweeting', 'at', '#', 'RISE_Austin', ',', 'it', 'was', 'dead', '!', ' ', 'I', 'need', 'to', 'upgrade', '.', 'Plugin', 'stations', 'at', '#', 'SXSW', '.']\n"
     ]
    }
   ],
   "source": [
    "# Create list of word tokens\n",
    "token_list = []\n",
    "for token in my_doc:\n",
    "    token_list.append(token.text)\n",
    "print(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered Sentence: [.@wesley83, 3, G, iPhone, ., 3, hrs, tweeting, #, RISE_Austin, ,, dead, !,  , need, upgrade, ., Plugin, stations, #, SXSW, .]\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "#Implementation of stop words:\n",
    "filtered_sent=[]\n",
    "\n",
    "#  \"nlp\" Object is used to create documents with linguistic annotations.\n",
    "doc = nlp(text)\n",
    "\n",
    "# filtering stop words\n",
    "for word in doc:\n",
    "    if word.is_stop==False:\n",
    "        filtered_sent.append(word)\n",
    "print(\"Filtered Sentence:\",filtered_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "New buzz? &quot;@mention Google to Launch Major New Social Network Called Circles, Possibly Today {link} rt @mention #sxsw&quot;"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = nlp(df['tweet_text'][100])\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "entities=[(i, i.label_, i.label) for i in tweet.ents]\n",
    "entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parsing out unique words in positive versus neutral/negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweet_text = df[df['target'] == 1]['tweet_text']\n",
    "neut_neg_tweet_text = df[df['target'] == 0]['tweet_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6769"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_token_list = []\n",
    "\n",
    "for tweet in positive_tweet_text:\n",
    "    tweet = nlp(tweet)\n",
    "    for token in tweet:\n",
    "        pos_token_list.append(token.text)\n",
    "        \n",
    "pos_token_list_set = set(pos_token_list)\n",
    "\n",
    "len(pos_token_list_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10893"
      ]
     },
     "execution_count": 879,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neut_neg_token_list = []\n",
    "\n",
    "for tweet in neut_neg_tweet_text:\n",
    "    tweet = nlp(tweet)\n",
    "    for token in tweet:\n",
    "        neut_neg_token_list.append(token.text)\n",
    "        \n",
    "neut_neg_token_list_set = set(neut_neg_token_list)\n",
    "\n",
    "len(neut_neg_token_list_set)\n",
    "# 60% more unique than positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neut_neg_token_list_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_token_list_unique = pos_token_list_set.difference(neut_neg_token_list_set)\n",
    "# new set with elements in pos_token_list_set but not in neut_neg_token_list_set\n",
    "len(pos_token_list_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neut_neg_token_list_unique = neut_neg_token_list_set.difference(pos_token_list_set)\n",
    "# new set with elements in neut_neg_token_list_set but not in pos_token_list_set\n",
    "len(neut_neg_token_list_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try Parsing with Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_tweet_text2 = df[df['target'] == 1]['token_tweet']\n",
    "neut_neg_tweet_text2 = df[df['target'] == 0]['token_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5112"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_token_list2 = []\n",
    "\n",
    "for tweet in positive_tweet_text:\n",
    "    for token in tweet:\n",
    "        pos_token_list2.append(token)\n",
    "        \n",
    "len(set(pos_token_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_token_list_set2 = set(pos_token_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8173"
      ]
     },
     "execution_count": 878,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neut_neg_token_list2 = []\n",
    "\n",
    "for tweet in neut_neg_tweet_text2:\n",
    "    for token in tweet:\n",
    "        neut_neg_token_list2.append(token)\n",
    "        \n",
    "len(set(neut_neg_token_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "neut_neg_token_list_set2 = set(neut_neg_token_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1922"
      ]
     },
     "execution_count": 887,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_token_list_unique2 = pos_token_list_set2.difference(neut_neg_token_list_set2)\n",
    "# new set with elements in pos_token_list_set but not in neut_neg_token_list_set\n",
    "len(pos_token_list_unique2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sitelinkphing',\n",
       " 'hashphfandango',\n",
       " 'sessionsnxt',\n",
       " 'itslinkphing',\n",
       " 'relaxinglinkphputer',\n",
       " 'hashphdesignflaws',\n",
       " 'inde',\n",
       " 'everbody',\n",
       " 'ripped',\n",
       " 'passage',\n",
       " 'applinkphe',\n",
       " 'sprinkle',\n",
       " 'offerlinkphpared',\n",
       " 'salesperson',\n",
       " 'singing',\n",
       " 'á¾_î¾ð_____ôèï_ãöýçü¼¼',\n",
       " 'iconbuffet',\n",
       " 'goona',\n",
       " 'measuring',\n",
       " 'everyday',\n",
       " 'incredibly',\n",
       " 'drafthouse',\n",
       " 'rigeur',\n",
       " 'articulate',\n",
       " 'presos',\n",
       " 'amused',\n",
       " 'nick',\n",
       " 'smoke',\n",
       " 'starbu',\n",
       " 'hashphempowered',\n",
       " 'enchanting',\n",
       " 'twitpic',\n",
       " 'itme',\n",
       " 'hashphcircusmash',\n",
       " 'wot',\n",
       " 'filming',\n",
       " 'scannercreators',\n",
       " 'todo',\n",
       " 'tenet',\n",
       " 'wowûïmenph',\n",
       " '11th',\n",
       " 'hashphagchathashphsxsw',\n",
       " 'julie',\n",
       " 'wpeople',\n",
       " 'smooth',\n",
       " 'hashphfxsw',\n",
       " 'locationmap',\n",
       " 'palette',\n",
       " 'brilliance',\n",
       " 'sxsurrogateslinkph',\n",
       " 'appslinkphing',\n",
       " 'hashphpopupstoreû',\n",
       " 'v5',\n",
       " 'installs',\n",
       " 'methinks',\n",
       " 'innovating',\n",
       " 'penguin',\n",
       " 'lineand',\n",
       " 'hashphpseudoretweet',\n",
       " 'attracting',\n",
       " 'phew',\n",
       " 'hashphgooglebread',\n",
       " 'kenny',\n",
       " 'mercy',\n",
       " 'solves',\n",
       " 'seereally',\n",
       " 'spasmatics',\n",
       " 'sunglass',\n",
       " 'hashph4sqs',\n",
       " 'hashphsxsw4japan',\n",
       " 'balcony',\n",
       " 'meeti',\n",
       " 'luckily',\n",
       " 'hashphgamesfortv',\n",
       " 'hashphimanoutcast',\n",
       " 'wishful',\n",
       " 'moonbot',\n",
       " 'kickass',\n",
       " '59p',\n",
       " 'linkphtcog4gzypv',\n",
       " 'hashplinkphcom',\n",
       " 'affair',\n",
       " 'regretting',\n",
       " 'fluid',\n",
       " 'dictaphone',\n",
       " 'cohen',\n",
       " 'laptopcharger',\n",
       " 'hashphwinwin',\n",
       " 'ferriss',\n",
       " 'leash',\n",
       " 'flask',\n",
       " 'implementing',\n",
       " 'mustresistmactemptation',\n",
       " 'ipadperson',\n",
       " 'tax',\n",
       " 'hashphcwc2011',\n",
       " 'fancrazed',\n",
       " 'hashphpakistan',\n",
       " 'conferencesevents',\n",
       " 'storeyou',\n",
       " 'catching',\n",
       " '530',\n",
       " 'ical',\n",
       " 'hashphtelework',\n",
       " 'mystery',\n",
       " 'threequarters',\n",
       " 'projecting',\n",
       " 'winsåêsxsw',\n",
       " 'fellowship',\n",
       " 'quarantined',\n",
       " 'cordless',\n",
       " 'helped',\n",
       " 'frickin',\n",
       " 'seemingly',\n",
       " 'doubly',\n",
       " 'ferris',\n",
       " 'thewildernessdowntownlinkph',\n",
       " 'unloaded',\n",
       " 'meûójust',\n",
       " 'alllinkphers',\n",
       " 'jailbreak',\n",
       " 'hashphnumbassonfloor',\n",
       " 'omitting',\n",
       " 'shat',\n",
       " 'leading',\n",
       " 'hashphteamandroidsxsw',\n",
       " 'tvontheradio',\n",
       " 'hoo',\n",
       " 'throwing',\n",
       " 'invisible',\n",
       " 'hashphstumbledupon',\n",
       " 'unfair',\n",
       " 'hashphairline',\n",
       " 'epicurious',\n",
       " 'lightbulb',\n",
       " 'initial',\n",
       " 'digitally',\n",
       " 'impressed',\n",
       " 'freaking',\n",
       " 'snapping',\n",
       " 'coolhaus',\n",
       " 'environmental',\n",
       " 'papa',\n",
       " 'overshadowing',\n",
       " 'hashphprettycool',\n",
       " 'hashphdiet',\n",
       " 'lookin',\n",
       " 'relation',\n",
       " 'observation',\n",
       " 'iloveasurprise',\n",
       " 'sliced',\n",
       " 'cnt',\n",
       " 'appû',\n",
       " 'sporting',\n",
       " 'wundertablet',\n",
       " 'roomhashphnokiaconnects',\n",
       " 'charm',\n",
       " 'hashphview512',\n",
       " 'resulting',\n",
       " 'artistic',\n",
       " 'francisco',\n",
       " 'chalked',\n",
       " 'underestimate',\n",
       " 'jetlag',\n",
       " 'hashphrandom',\n",
       " 'mega',\n",
       " 'yowza',\n",
       " 'initiative',\n",
       " 'hashphsxswchi',\n",
       " 'bloggable',\n",
       " 'indicates',\n",
       " 'menphr',\n",
       " 'hashphandroids',\n",
       " 'overlay',\n",
       " 'epicenter',\n",
       " 'tabletipad',\n",
       " 'pour',\n",
       " 'ubertwitter',\n",
       " 'ðü',\n",
       " 'hashphplaysxswû',\n",
       " 'obvious',\n",
       " 'aclus',\n",
       " 'ray',\n",
       " '55',\n",
       " 'reminding',\n",
       " 'fanboy',\n",
       " 'photoes',\n",
       " 'evernote',\n",
       " 'qualified',\n",
       " 'dayfrom',\n",
       " 'copia',\n",
       " 'tkts',\n",
       " 'geekest',\n",
       " 'facebooklinkphpowermat',\n",
       " 'mmod',\n",
       " 'delving',\n",
       " 'jared',\n",
       " 'solid',\n",
       " 'admission',\n",
       " 'xmllinkphbines',\n",
       " 'logical',\n",
       " 'recipient',\n",
       " 'hashphigottagetit',\n",
       " 'cntr',\n",
       " 'atm',\n",
       " 'thelinkphplete',\n",
       " 'steady',\n",
       " 'depeche',\n",
       " 'gayno',\n",
       " 'untapped',\n",
       " 'neumann',\n",
       " 'temperature',\n",
       " 'hashphdtas',\n",
       " 'conversion',\n",
       " 'throwin',\n",
       " 'hashphsaysshewithoutanipad',\n",
       " 'abuzz',\n",
       " 'farmville',\n",
       " 'whoooooo',\n",
       " 'wonderful',\n",
       " 'suckling',\n",
       " 'hidden',\n",
       " 'hashphweekend',\n",
       " 'partner',\n",
       " 'worker',\n",
       " 'rite',\n",
       " 'ado',\n",
       " 'inapp',\n",
       " 'dimensional',\n",
       " 'hashphscience',\n",
       " 'sd',\n",
       " 'ordinance',\n",
       " 'dexteria',\n",
       " 'fetishism',\n",
       " 'southpaw',\n",
       " 'ti',\n",
       " 'side',\n",
       " 'rockaroke',\n",
       " 'hashphgoogleblog',\n",
       " 'bart',\n",
       " 'hashphlivingthedream',\n",
       " 'fullswing',\n",
       " 'moody',\n",
       " 'exquisite',\n",
       " 'hashphzaarly',\n",
       " 'callooh',\n",
       " 'date',\n",
       " 'qho',\n",
       " 'yawn',\n",
       " 'replenished',\n",
       " 'nextflix',\n",
       " 'karateka',\n",
       " 'eyeballed',\n",
       " 'hashphsheeple',\n",
       " 'winsåêhashphsxsw',\n",
       " 'thick',\n",
       " 'hashphprepared',\n",
       " 'ship',\n",
       " 'griffin',\n",
       " 'goodi',\n",
       " 'ûviagra',\n",
       " 'suddenly',\n",
       " 'prehashphsxsw',\n",
       " 'omgjk',\n",
       " 'denotes',\n",
       " 'hhaha',\n",
       " 'smartlinkphpany',\n",
       " 'hashphlifelinetotheworld',\n",
       " 'practice',\n",
       " 'monger',\n",
       " 'streetan',\n",
       " 'macchiato',\n",
       " 'goodguide',\n",
       " 'globalbestaward',\n",
       " 'insightful',\n",
       " 'rachael',\n",
       " 'hashphaccesssxsw',\n",
       " 'underwire',\n",
       " 'freelinkph',\n",
       " 'catfight',\n",
       " 'blinksale',\n",
       " 'hashphgadgetenvy',\n",
       " 'visualize',\n",
       " 'booyah',\n",
       " 'smut',\n",
       " 'porting',\n",
       " 'spanking',\n",
       " 'mq',\n",
       " 'hashphsxswhashph',\n",
       " 'thin',\n",
       " 'dangling',\n",
       " 'goin',\n",
       " 'implementation',\n",
       " 'bashing',\n",
       " 'appeal',\n",
       " 'shelf',\n",
       " 'wrapper',\n",
       " 'louisiana',\n",
       " 'soul',\n",
       " 'critique',\n",
       " 'trampling',\n",
       " 'ninjafinder',\n",
       " 'hashphvip',\n",
       " 'wasting',\n",
       " 'sec',\n",
       " 'onhashphsxsw',\n",
       " 'forecast',\n",
       " 'padless',\n",
       " 'hashphchevysmc',\n",
       " 'heavenly',\n",
       " 'banksmoney',\n",
       " 'forbes',\n",
       " 'traveller',\n",
       " 'everylinkphpany',\n",
       " 'bummer',\n",
       " 'khan',\n",
       " 'googlesponsored',\n",
       " 'ª',\n",
       " 'gadgetaddicted',\n",
       " 'inferior',\n",
       " 'hashphcourtyard',\n",
       " 'consciously',\n",
       " 'wodpress',\n",
       " 'hashphyouneedthis',\n",
       " 'reach',\n",
       " 'legacy',\n",
       " 'strap',\n",
       " 'softball',\n",
       " 'stabilizer',\n",
       " 'authenticator',\n",
       " 'swish',\n",
       " 'tight',\n",
       " 'bread',\n",
       " 'hashphappletakingoverworld',\n",
       " 'hashphorly',\n",
       " 'hashphweb30',\n",
       " 'landlord',\n",
       " 'worthwhile',\n",
       " 'hashphpgi',\n",
       " 'deeper',\n",
       " 'jinx',\n",
       " '3blks',\n",
       " 'crave',\n",
       " 'hashphletschangetheworld',\n",
       " 'dayweekend',\n",
       " 'cruze',\n",
       " 'chart',\n",
       " 'blockguess',\n",
       " 'consume',\n",
       " 'rfid',\n",
       " 'handwriting',\n",
       " 'hashphgooddeed',\n",
       " 'hashphhappydance',\n",
       " 'hashphchargin2diffphonesatonce',\n",
       " 'shortcut',\n",
       " '315',\n",
       " 'torture',\n",
       " 'kit',\n",
       " 'unlockable',\n",
       " 'chic',\n",
       " 'apac',\n",
       " 'wozniak',\n",
       " 'virgin',\n",
       " 'heatmap',\n",
       " 'hashphsxswhashphapple',\n",
       " 'whale',\n",
       " 'behavior',\n",
       " 'disrupts',\n",
       " 'elevation',\n",
       " 'macpc',\n",
       " 'virtually',\n",
       " 'planting',\n",
       " 'dealing',\n",
       " 'tnx',\n",
       " 'itunesifr3dw',\n",
       " 'hashphmyegc',\n",
       " 'fastest',\n",
       " 'hashphwebvisions',\n",
       " 'mel',\n",
       " 'hashphpersonalcloud',\n",
       " 'murphy',\n",
       " 'yourlinkphmunicationsûª',\n",
       " 'marcelosomers',\n",
       " 'v30',\n",
       " 'hashphsxswsters',\n",
       " 'blast',\n",
       " 'largest',\n",
       " 'gorgeous',\n",
       " 'morphie',\n",
       " 'explode',\n",
       " 'housecat',\n",
       " 'fathom',\n",
       " 'nfl',\n",
       " 'mapquest',\n",
       " 'officer',\n",
       " 'hashphfuckyeah',\n",
       " 'countering',\n",
       " 'petting',\n",
       " 'pg',\n",
       " 'wkend',\n",
       " 'gpsaware',\n",
       " 'austinbound',\n",
       " 'tdg',\n",
       " 'kingston',\n",
       " 'vinteresting',\n",
       " 'brit',\n",
       " 'progression',\n",
       " '5060',\n",
       " 'withdrawal',\n",
       " 'barging',\n",
       " 'rubbing',\n",
       " 'zms',\n",
       " 'ordering',\n",
       " 'androidlinkphmunity',\n",
       " 'wannabehipsters',\n",
       " 'analysis',\n",
       " 'relaxed',\n",
       " 'hashphheattracker',\n",
       " 'streetviewlike',\n",
       " 'hashphlamesauce',\n",
       " 'rollout',\n",
       " 'detailslinkphing',\n",
       " 'l8er',\n",
       " 'understanding',\n",
       " 'buzzrtph',\n",
       " 'starry',\n",
       " 'partyu',\n",
       " 'hashphjustinjustinjustin',\n",
       " 'latû',\n",
       " 'kiddie',\n",
       " 'sfo',\n",
       " 'hashphtaccsxsw',\n",
       " 'hashphsxswwill',\n",
       " 'orange',\n",
       " 'hashphsxswsounds',\n",
       " 'rescuing',\n",
       " '3x',\n",
       " 'wandered',\n",
       " 'teeny',\n",
       " 'timed',\n",
       " 'linescarfing',\n",
       " 'hashpholdsko0l',\n",
       " 'ipoo',\n",
       " 'iads',\n",
       " 'armadillo',\n",
       " 'hashphflashspecial',\n",
       " 'caruse',\n",
       " 'adfonic',\n",
       " 'ning',\n",
       " 'centric',\n",
       " 'anylinkphputing',\n",
       " 'linkphtcoa3xvwc6',\n",
       " 'chairhashphsxsw',\n",
       " 'hashphvirtualoffice',\n",
       " 'colour',\n",
       " 'hashphdokobots',\n",
       " 'parenthesis',\n",
       " 'hashphmylunch',\n",
       " 'retiring',\n",
       " 'bricklins',\n",
       " 'hashphvegas',\n",
       " 'brah',\n",
       " 'onness',\n",
       " 'hashphipad2time',\n",
       " 'settle',\n",
       " 'awhile',\n",
       " 'consistent',\n",
       " 'semantic',\n",
       " 'supply',\n",
       " 'soos',\n",
       " 'betterthey',\n",
       " 'alan',\n",
       " 'artificial',\n",
       " 'biomimicry',\n",
       " 'ijustshatmyfanboyknickers',\n",
       " 'mirroring',\n",
       " 'imho',\n",
       " 'dedication',\n",
       " 'hashphlovemusicapi',\n",
       " 'panorama',\n",
       " 'applinkphes',\n",
       " 'conveniently',\n",
       " 'judging',\n",
       " 'rlinkphmended',\n",
       " 'hopkins',\n",
       " 'hashphshowusyouricrazy',\n",
       " 'pun',\n",
       " 'recovery',\n",
       " 'sore',\n",
       " 'rei',\n",
       " 'pure',\n",
       " 'rematch',\n",
       " 'argument',\n",
       " 'notesphotos',\n",
       " 'define',\n",
       " 'formula',\n",
       " 'bin',\n",
       " 'storesexcept',\n",
       " 'rlinkphds',\n",
       " 'eddy',\n",
       " 'ip4',\n",
       " 'iosiphone',\n",
       " 'dehumanizing',\n",
       " 'trackpads',\n",
       " 'succeed',\n",
       " 'hashphdorkinout',\n",
       " 'hashphdfw',\n",
       " 'hipstapaks',\n",
       " 'entertaining',\n",
       " 'achieve',\n",
       " 'hashphipadmadness',\n",
       " 'steampunk',\n",
       " 'hashphbettercloudlinkphputing',\n",
       " 'blueray',\n",
       " 'miracle',\n",
       " 'hashphgeekspringbreak',\n",
       " 'awesomely',\n",
       " 'rf',\n",
       " 'alt',\n",
       " 'usefulness',\n",
       " 'blackbook',\n",
       " 'thatlinkphes',\n",
       " 'intelligence',\n",
       " 'hashphrad',\n",
       " 'brisk',\n",
       " 'blacked',\n",
       " 'unscientific',\n",
       " 'motivator',\n",
       " 'iphonecharger',\n",
       " 'malt',\n",
       " 'crasher',\n",
       " 'theylinkphpletely',\n",
       " 'dawned',\n",
       " 'momentit',\n",
       " 'lindsay',\n",
       " 'handicapped',\n",
       " 'usurped',\n",
       " 'passenger',\n",
       " 'quarter',\n",
       " 'plied',\n",
       " 'coincide',\n",
       " 'cow',\n",
       " 'haslinkphe',\n",
       " 'theylinkphe',\n",
       " 'minimaglight',\n",
       " 'hashphbehance',\n",
       " 'basket',\n",
       " 'ingenious',\n",
       " 'davisdesigning',\n",
       " 'tm',\n",
       " 'resourceful',\n",
       " 'harris',\n",
       " 'nur',\n",
       " 'douchebaggery',\n",
       " 'hashpheatdrinktweet',\n",
       " 'addiction',\n",
       " 'bernd',\n",
       " 'shotgunûª',\n",
       " 'smartlinkphpanyapple',\n",
       " 'king',\n",
       " 'disneyland',\n",
       " 'outlook',\n",
       " 'tee',\n",
       " 'hipstergeekstartup',\n",
       " '2åêhashphtechcrunch',\n",
       " 'solely',\n",
       " 'mealtime',\n",
       " 'messenger',\n",
       " 'skyfire',\n",
       " 'hashphmidem',\n",
       " 'displaying',\n",
       " 'badgeless',\n",
       " 'wwwsocialmediabumtumblrlinkph',\n",
       " 'finish',\n",
       " 'hashphjk',\n",
       " 'marker',\n",
       " 'cnnmoney',\n",
       " 'overtaken',\n",
       " 'virginity',\n",
       " 'hashphspiltbeer',\n",
       " 'macbookpro',\n",
       " 'rebel',\n",
       " 'tolinkphfort',\n",
       " 'taariq',\n",
       " 'bluezoom',\n",
       " 'hashphrewardswagon',\n",
       " 'hashphnetworking',\n",
       " 'champ',\n",
       " 'revolt',\n",
       " 'brightens',\n",
       " 'idk',\n",
       " 'captured',\n",
       " 'hashphlockout',\n",
       " 'rlinkphmends',\n",
       " 'svcs',\n",
       " 'hashphaus',\n",
       " '2honor',\n",
       " 'enviro',\n",
       " 'jerk',\n",
       " 'hashphtoocoolforsxswanyway',\n",
       " 'profit',\n",
       " 'dance',\n",
       " 'permanent',\n",
       " 'tractor',\n",
       " 'rediculous',\n",
       " 'korean',\n",
       " 'republic',\n",
       " 'omgfree',\n",
       " 'smurfs',\n",
       " 'severely',\n",
       " 'paolo',\n",
       " 'hashphfuturecast',\n",
       " 'dis',\n",
       " 'hitlantis',\n",
       " 'hashphvmware',\n",
       " 'hashphmediaû',\n",
       " 'cocoon',\n",
       " 'v12',\n",
       " 'benefit',\n",
       " 'iphonewii',\n",
       " 'received',\n",
       " 'hashphredbullbpm',\n",
       " 'magnetic',\n",
       " 'hashphbynd',\n",
       " 'reeling',\n",
       " 'awwww',\n",
       " 'hashphvoicefeed',\n",
       " 'peddle',\n",
       " 'develop',\n",
       " 'petition',\n",
       " 'hashphnudgenudge',\n",
       " 'bylinkphpany',\n",
       " 'doodlelinkphpetition',\n",
       " 'housing',\n",
       " 'flannel',\n",
       " 'waste',\n",
       " 'busdev',\n",
       " 'changedlinkphmunications',\n",
       " 'ittttt',\n",
       " 'ther',\n",
       " 'alex',\n",
       " 'peeked',\n",
       " 'configuration',\n",
       " 'roadie',\n",
       " 'hashphhangover3',\n",
       " 'awe',\n",
       " 'responsibility',\n",
       " 'toured',\n",
       " 'adding',\n",
       " 'psyched',\n",
       " 'hole',\n",
       " 'chronicling',\n",
       " 'agent',\n",
       " 'alphagraphics',\n",
       " 'slowpoke',\n",
       " 'frontend',\n",
       " 'gasp',\n",
       " 'autistic',\n",
       " 'earbud',\n",
       " 'resist',\n",
       " 'vicariously',\n",
       " 'tube',\n",
       " 'riding',\n",
       " 'deviantartph',\n",
       " 'delight',\n",
       " 'onlinelinkphmunication',\n",
       " 'suffering',\n",
       " 'maximum',\n",
       " 'banged',\n",
       " 'hashphmarissamayer',\n",
       " 'rebranded',\n",
       " 'utilize',\n",
       " 'lifechanging',\n",
       " 'attendeesyou',\n",
       " 'matching',\n",
       " 'hashphpopplet',\n",
       " 'hashphitwillbemine',\n",
       " 'linkphbitlyhtdfim',\n",
       " 'webmail',\n",
       " 'hashphamex',\n",
       " 'hashphapple_store',\n",
       " '7200',\n",
       " 'acceptable',\n",
       " 'hashphsloanxsw',\n",
       " 'mayerlinkphes',\n",
       " 'httû',\n",
       " '120',\n",
       " 'todayim',\n",
       " 'reclaimed',\n",
       " 'crowdbeacon',\n",
       " 'hashphgitchococktailon',\n",
       " 'crackberry',\n",
       " 'tricked',\n",
       " 'designersdevs',\n",
       " 'grossed',\n",
       " 'passì',\n",
       " 'consumerfacing',\n",
       " 'hashphusdes',\n",
       " 'therelinkph',\n",
       " 'awesomeness',\n",
       " 'googlegays',\n",
       " 'hashphphotosharing',\n",
       " 'iphonemaking',\n",
       " 'expansion',\n",
       " 'tan',\n",
       " 'crafty',\n",
       " 'uppward',\n",
       " 'tmrw',\n",
       " 'guguchu',\n",
       " 'visualizing',\n",
       " 'howmto',\n",
       " 'dofollow',\n",
       " 'piping',\n",
       " 'carbon',\n",
       " 'tweetup',\n",
       " 'stellar',\n",
       " '2yrs',\n",
       " 'courtside',\n",
       " 'haystack',\n",
       " 'cheeky',\n",
       " 'appits',\n",
       " 'centre',\n",
       " 'undoubtedly',\n",
       " 'rimmed',\n",
       " 'onlinkphpany',\n",
       " 'hashphsuccess',\n",
       " 'escape',\n",
       " 'fì_r',\n",
       " 'visitorsû',\n",
       " 'spazmatic',\n",
       " 'hashphtechrockstar',\n",
       " 'breathtaking',\n",
       " 'acrosse',\n",
       " 'vidcamera',\n",
       " 'checkinthing',\n",
       " 'thomas',\n",
       " 'klick',\n",
       " 'hashphsxwsi',\n",
       " 'someday',\n",
       " 'sweetapple',\n",
       " 'wean',\n",
       " 'ipadtablet',\n",
       " 'anywhereuntil',\n",
       " 'lobbying',\n",
       " '210',\n",
       " 'hashphteam_android',\n",
       " 'nowyes',\n",
       " 'hashphponies',\n",
       " 'zagg',\n",
       " 'studentsforcleanwaterorgrsvp',\n",
       " 'deforestation',\n",
       " 'fixing',\n",
       " 'shoulda',\n",
       " 'unlocking',\n",
       " 'hawt',\n",
       " 'last',\n",
       " 'lifetime',\n",
       " 'obv',\n",
       " 'enlightening',\n",
       " 'howdy',\n",
       " 'fridaythe',\n",
       " 'ipadlinkphe',\n",
       " 'hashphcouch',\n",
       " '37',\n",
       " '320',\n",
       " 'hashphvb',\n",
       " 'lottery',\n",
       " 'hashphwoops',\n",
       " 'runaround',\n",
       " 'geekout',\n",
       " 'skier',\n",
       " 'linkphtumblrlinkphx6t1pi6av7',\n",
       " 'twofactor',\n",
       " 'hashphaugmentedreality',\n",
       " 'ifrom',\n",
       " 'hashpheurosxsw',\n",
       " 'principle',\n",
       " 'wevent',\n",
       " '0310apple',\n",
       " 'hashphgeekdate',\n",
       " 'fullforce',\n",
       " 'hoooooooooooooo',\n",
       " 'slick',\n",
       " 'aw',\n",
       " 'hashphfirstworldproblems',\n",
       " 'nontext',\n",
       " 'ûhoboûª',\n",
       " 'burst',\n",
       " 'hashphrockstache',\n",
       " 'overlaid',\n",
       " 'loyaltymobile',\n",
       " 'render',\n",
       " 'frustrated',\n",
       " 'willpower',\n",
       " 'nicely',\n",
       " 'intricate',\n",
       " 'inner',\n",
       " 'shamed',\n",
       " 'publiclinkphputers',\n",
       " 'onetoone',\n",
       " 'yeaayyy',\n",
       " 'macallan',\n",
       " 'hitlantislinkph',\n",
       " 'startupbus',\n",
       " 'incl',\n",
       " 'omgz',\n",
       " 'role',\n",
       " 'amigo',\n",
       " 'hashph1990style',\n",
       " '800',\n",
       " 'iphoneworkin',\n",
       " 'fusion',\n",
       " 'bat',\n",
       " 'fanboydom',\n",
       " 'hashphanybodywanttobuymeanipad2',\n",
       " 'intrestin',\n",
       " '10000',\n",
       " 'twice',\n",
       " 'lust',\n",
       " 'nba',\n",
       " 'vegan',\n",
       " 'homepage',\n",
       " 'hashphyoutube',\n",
       " 'sweeeeet',\n",
       " 'chump',\n",
       " 'ûhashphsmartcoverûª',\n",
       " 'detect',\n",
       " 'coolas',\n",
       " 'wholinkphes',\n",
       " 'tved',\n",
       " 'ia',\n",
       " 'food4thoughtjuxtaposed',\n",
       " 'riot',\n",
       " 'killn',\n",
       " 'hitops',\n",
       " 'hashphkeepaustinweird',\n",
       " 'roof',\n",
       " 'viewio',\n",
       " 'andlinkphplement',\n",
       " 'overview',\n",
       " 'joined',\n",
       " 'livesteam',\n",
       " 'hashphpowermattteam',\n",
       " 'yummy',\n",
       " 'knackered',\n",
       " 'callay',\n",
       " 'confines',\n",
       " 'hashphjobsco',\n",
       " 'hashphuncertainty',\n",
       " 'illegal',\n",
       " 'supposecheers',\n",
       " 'ouchhisshot',\n",
       " 'hoc',\n",
       " 'stogy',\n",
       " 'hashphfrood',\n",
       " 'affirmative',\n",
       " 'lugging',\n",
       " 'hashphgeekdilemma',\n",
       " 'congratulation',\n",
       " 'nab',\n",
       " 'stunning',\n",
       " 'mapstraffic',\n",
       " 'tub',\n",
       " 'antwoord',\n",
       " 'funlinkphes',\n",
       " 'synced',\n",
       " 'reasoning',\n",
       " 'scary',\n",
       " 'hashphbmm',\n",
       " 'jaw',\n",
       " 'convore',\n",
       " 'rendering',\n",
       " 'landmark',\n",
       " 'sweepstakes',\n",
       " 'hashphgenius',\n",
       " 'admired',\n",
       " 'incenticize',\n",
       " 'cite',\n",
       " 'aicn',\n",
       " 'ridicule',\n",
       " 'hashphcmswire',\n",
       " 'turkey',\n",
       " 'gettinng',\n",
       " 'damm',\n",
       " 'element',\n",
       " 'sings',\n",
       " 'tix',\n",
       " 'rub',\n",
       " 'wisconsin',\n",
       " 'lybian',\n",
       " 'forever',\n",
       " 'harnessing',\n",
       " 'writeoff',\n",
       " 'hated',\n",
       " 'arrives',\n",
       " 'hooting',\n",
       " 'pinoy',\n",
       " 'hashphù_¾',\n",
       " 'fundraising',\n",
       " 'television',\n",
       " 'hashphwoohoo',\n",
       " 'magnifying',\n",
       " 'lordy',\n",
       " 'soldout',\n",
       " 'nat',\n",
       " 'upside',\n",
       " 'newsworthy',\n",
       " 'hashphlonelyplanet',\n",
       " 'hashphhollrback',\n",
       " 'mental',\n",
       " 'wowwwwww',\n",
       " 'crazylong',\n",
       " 'fulltime',\n",
       " '15to1',\n",
       " 'proven',\n",
       " 'hashphîé',\n",
       " 'martini',\n",
       " 'syked',\n",
       " 'festivalexplorer',\n",
       " 'hashphnotionink',\n",
       " 'bite',\n",
       " 'è',\n",
       " 'hashphtexting',\n",
       " 'haslinkphpletely',\n",
       " 'linkphsmarketandroidlinkphdetailsidlinkphborderstyloretrollect',\n",
       " 'kthxbai',\n",
       " 'hashphgeekout',\n",
       " 'ninehour',\n",
       " 'powering',\n",
       " 'alinkphmodate',\n",
       " 'spread',\n",
       " 'hashphgeeksrule',\n",
       " 'socnet',\n",
       " 'stealing',\n",
       " 'hashphnewapplestoreaustin',\n",
       " 'patience',\n",
       " 'planzai',\n",
       " 'umshini',\n",
       " 'yourelinkphing',\n",
       " 'tunage',\n",
       " 'imlinkphing',\n",
       " 'maudies',\n",
       " 'uncharged',\n",
       " 'hashphsxprotect',\n",
       " 'hashphtoolongforme',\n",
       " 'pariah',\n",
       " 'frabjous',\n",
       " 'capitol',\n",
       " 'iphone4s',\n",
       " 'sweeeet',\n",
       " 'bavc',\n",
       " 'detection',\n",
       " 'iûªll',\n",
       " '3linkphing',\n",
       " 'hashphshame',\n",
       " 'w00',\n",
       " 'kh',\n",
       " 'coinsidence',\n",
       " 'education',\n",
       " 'bloomberg',\n",
       " 'mountain',\n",
       " 'hashphbt',\n",
       " 'mount',\n",
       " 'booksconferences',\n",
       " 'superfast',\n",
       " 'hashphgeekery',\n",
       " 'dividend',\n",
       " 'hashphstillonamacbook',\n",
       " 'aristotle',\n",
       " 'fantastico',\n",
       " 'lion',\n",
       " 'yield',\n",
       " 'attractive',\n",
       " 'gawking',\n",
       " 'weinschenk',\n",
       " 'chunky',\n",
       " 'talib',\n",
       " '40min',\n",
       " 'hashphtexasevery',\n",
       " 'hashphchevysxsw',\n",
       " 'suffered',\n",
       " 'waking',\n",
       " 'rainjacket',\n",
       " 'felix',\n",
       " 'hashphmktg',\n",
       " 'grooving',\n",
       " 'ratingrlinkphmendation',\n",
       " 'franco',\n",
       " 'sangre',\n",
       " 'locationaware',\n",
       " 'livingû',\n",
       " 'knockout',\n",
       " 'ridculous',\n",
       " 'cupertino',\n",
       " 'hashphpissedimnotgoingtosxsw',\n",
       " 'coding',\n",
       " 'bookbook',\n",
       " 'q7a',\n",
       " '35hour',\n",
       " 'sighting',\n",
       " ...}"
      ]
     },
     "execution_count": 888,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_token_list_unique2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4983"
      ]
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neut_neg_token_list_unique2 = neut_neg_token_list_set2.difference(pos_token_list_set2)\n",
    "# new set with elements in neut_neg_token_list_set but not in pos_token_list_set\n",
    "len(neut_neg_token_list_unique2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'voluntary',\n",
       " 'hashphtherocksreport',\n",
       " 'snowflake',\n",
       " 'ridley',\n",
       " 'foråêhashphiphone',\n",
       " '459pm',\n",
       " 'boothe',\n",
       " 'checklist',\n",
       " 'islinkphpeting',\n",
       " 'hashphtabletwars',\n",
       " 'hashphmusicmonday',\n",
       " 'se',\n",
       " 'balance',\n",
       " 'sprinkler',\n",
       " 'hashphwiiings',\n",
       " 'ridonkulous',\n",
       " 'math',\n",
       " 'aggregated',\n",
       " 'reference',\n",
       " 'hashphproductive',\n",
       " 'cartridge',\n",
       " 'citymarket',\n",
       " 'employed',\n",
       " 'hulu',\n",
       " 'imparted',\n",
       " 'dudesjust',\n",
       " 'jackie',\n",
       " 'nonmacbook',\n",
       " 'cellbots',\n",
       " 'drew',\n",
       " 'hashphsmccolumbus',\n",
       " 'swimsuit',\n",
       " 'insidious',\n",
       " 'promos',\n",
       " 'hashphehteam',\n",
       " 'fanbois',\n",
       " 'tribunelinkphe',\n",
       " 'glitch',\n",
       " 'lined',\n",
       " 'hashphbeevil',\n",
       " 'meanness',\n",
       " 'pointing',\n",
       " 'splendor',\n",
       " 'advertisingcheckins',\n",
       " 'contû',\n",
       " 'paging',\n",
       " 'plutopia',\n",
       " 'den',\n",
       " 'slope',\n",
       " 'cellphone',\n",
       " 'sex',\n",
       " 'typ63mmam7w3',\n",
       " 'twtng',\n",
       " 'marcins',\n",
       " 'discussing',\n",
       " 'hashphbegger',\n",
       " 'ingredient',\n",
       " 'hashphcbs',\n",
       " 'hashphgrauniad',\n",
       " 'hashphlocal',\n",
       " 'probar',\n",
       " '031311',\n",
       " 'roasted',\n",
       " 'arthaus',\n",
       " 'mobilefirst',\n",
       " '3bil',\n",
       " 'pake',\n",
       " 'skype',\n",
       " 'sheer',\n",
       " 'ding',\n",
       " 'hashphsaytextson',\n",
       " 'hashphbadform',\n",
       " 'diagram',\n",
       " 'broke',\n",
       " 'streamlined',\n",
       " 'cruisin',\n",
       " 'ounce',\n",
       " 'collecting',\n",
       " 'linney',\n",
       " 'mcrees',\n",
       " 'sokinda',\n",
       " 'roundup',\n",
       " 'hashphwireless',\n",
       " 'chick',\n",
       " 'juwan',\n",
       " 'nonhashphsxswi',\n",
       " 'chilicheese',\n",
       " 'lwr',\n",
       " 'hashphpr20chat',\n",
       " 'menphm',\n",
       " '800115959p',\n",
       " 'nowhashphsxsw',\n",
       " 'dotrightsgoogle',\n",
       " '10mins',\n",
       " 'hashphstayingalive',\n",
       " 'û¼',\n",
       " 'handsfree',\n",
       " 'foråêiphone',\n",
       " 'neuf',\n",
       " 'hashphsmx',\n",
       " 'talktext',\n",
       " 'pete',\n",
       " 'name',\n",
       " 'mechanical',\n",
       " 'poem',\n",
       " 'argh',\n",
       " 'amer',\n",
       " 'quinn',\n",
       " 'hashphiphoneapp',\n",
       " 'willlinkphbine',\n",
       " '1850',\n",
       " 'hashphandroidcrunch',\n",
       " 'payin',\n",
       " 'ser',\n",
       " 'smugness',\n",
       " 'naked',\n",
       " 'hackerspace',\n",
       " 'bandwagonlinkph',\n",
       " 'addr',\n",
       " 'frustration',\n",
       " 'revamped',\n",
       " 'hashph11ntc',\n",
       " 'hashphsxswgoogle',\n",
       " 'hashphcab',\n",
       " 'backpacking',\n",
       " '120035959p',\n",
       " 'popoup',\n",
       " 'hashphmeet',\n",
       " 'chzbrgr',\n",
       " 'sanctuary',\n",
       " 'boil',\n",
       " 'hashphbilllee',\n",
       " 'editorûªs',\n",
       " 'tho',\n",
       " 'hashphmeasure',\n",
       " 'hashphdrumbeat',\n",
       " 'ps3',\n",
       " 'hashphimconfused',\n",
       " 'wolfram',\n",
       " 'downloadable',\n",
       " 'ability',\n",
       " 'verge',\n",
       " 'etiquette',\n",
       " 'huh',\n",
       " 'hashphbetterthingstodo',\n",
       " 'motley',\n",
       " 'postmark',\n",
       " 'kiip',\n",
       " 'hashphnewsweek',\n",
       " 'trumping',\n",
       " 'yyz',\n",
       " 'hashphsxswipad',\n",
       " 'nadja',\n",
       " 'demon',\n",
       " 'hashphcss',\n",
       " 'dir',\n",
       " 'copyright',\n",
       " 'hashphironic',\n",
       " 'hashphsocialnetworking',\n",
       " 'panelsparties',\n",
       " 'blogged',\n",
       " 'nik',\n",
       " 'tsunamithe',\n",
       " 'mayhem',\n",
       " 'tag',\n",
       " 'launchrock',\n",
       " 'spam',\n",
       " 'dtwn',\n",
       " 'emarketer',\n",
       " 'feedback',\n",
       " 'wrap',\n",
       " 'deed',\n",
       " 'ahi',\n",
       " 'punchout',\n",
       " 'require',\n",
       " 'stress',\n",
       " 'hashphjustsayin',\n",
       " 'hashphspeechtherapy',\n",
       " 'hashphwp7dev',\n",
       " 'inevitable',\n",
       " '175',\n",
       " 'ample',\n",
       " 'kyping',\n",
       " 'ditch',\n",
       " 'spokewoman',\n",
       " 'shake',\n",
       " 'reasonable',\n",
       " 'smarmcake',\n",
       " 'tryna',\n",
       " 'hashphsxswåêlinkph',\n",
       " 'horrible',\n",
       " '150û',\n",
       " 'hashphapi',\n",
       " 'duking',\n",
       " 'aight',\n",
       " 'period',\n",
       " 'chose',\n",
       " 'lulling',\n",
       " 'hashphsxswfail',\n",
       " 'involved',\n",
       " 'registeringviewing',\n",
       " 'hashphproject314',\n",
       " 'hashphposterous_events',\n",
       " 'hashphappsavvy',\n",
       " 'interfacecontrols',\n",
       " 'no',\n",
       " 'piercings',\n",
       " 'cardless',\n",
       " 'hashphyelp',\n",
       " 'yonkers',\n",
       " 'greatlinkphparison',\n",
       " 'spotlighting',\n",
       " 'dialy',\n",
       " 'abba',\n",
       " 'ïà',\n",
       " 'strawberry',\n",
       " 'hashphbooks',\n",
       " 'warwick',\n",
       " 'ûïbestû',\n",
       " 'realty',\n",
       " 'primo',\n",
       " 'hashphtokii',\n",
       " 'daylight',\n",
       " 'wayfarer',\n",
       " 'hashphleanux',\n",
       " 'scoop',\n",
       " 'thereû',\n",
       " 'agility',\n",
       " 'capital',\n",
       " 'hashphsxswupdates',\n",
       " 'producs',\n",
       " 'aps',\n",
       " 'wth',\n",
       " 'googlehashphsxsw',\n",
       " 'arwords',\n",
       " 'hashphsnubor',\n",
       " 'poked',\n",
       " 'n31',\n",
       " 'cornered',\n",
       " 'inane',\n",
       " 'nerdiest',\n",
       " 'retarded',\n",
       " 'bearded',\n",
       " 'skipping',\n",
       " 'yobongoed',\n",
       " 'bloody',\n",
       " 'beltclipgadgetholster',\n",
       " 'hashphquake',\n",
       " '6thish',\n",
       " 'hashphnecro',\n",
       " 'verpixelungsrechtûóthe',\n",
       " 'poster',\n",
       " 'hollergram',\n",
       " '1500',\n",
       " 'mouth',\n",
       " 'hashphgeek_games',\n",
       " 'dropbox',\n",
       " 'unveils',\n",
       " 'parabolico_bh',\n",
       " 'publicize',\n",
       " 'mtg',\n",
       " 'hashphdtsxsw',\n",
       " 'donating',\n",
       " 'hashphapplesxsw',\n",
       " 'cooper',\n",
       " 'omarg',\n",
       " 'log',\n",
       " 'hashphcmsxsw',\n",
       " 'explain',\n",
       " 'sits',\n",
       " 'outa',\n",
       " 'burlesque',\n",
       " 'newlinkphpetition',\n",
       " 'overthere',\n",
       " 'sxswlinkphe',\n",
       " 'firefighter',\n",
       " 'dtphlinkphû',\n",
       " 'hoax',\n",
       " 'limp',\n",
       " 'attendong',\n",
       " 'havelinkphe',\n",
       " 'cha',\n",
       " 'maurice',\n",
       " 'soundtrax',\n",
       " 'loom',\n",
       " 'journalsim',\n",
       " 'kelt',\n",
       " 'hashphiwantacr48',\n",
       " 'consolidate',\n",
       " 'gearing',\n",
       " 'unstable',\n",
       " 'hashphlongform',\n",
       " '3045',\n",
       " 'benmcgraw',\n",
       " 'arboretum',\n",
       " 'whatûªs',\n",
       " 'hashphontologists',\n",
       " 'sundance',\n",
       " 'dvrs',\n",
       " 'downtime',\n",
       " 'porque',\n",
       " 'alllinkphpany',\n",
       " 'interoperability',\n",
       " 'insanity',\n",
       " 'turnstone',\n",
       " 'ûïbuttons',\n",
       " 'bio',\n",
       " 'reprieve',\n",
       " 'medical',\n",
       " 'hashphimthetype',\n",
       " 'stow',\n",
       " '230',\n",
       " 'hashphletshookup',\n",
       " 'concentrate',\n",
       " 'intuitive',\n",
       " 'mania',\n",
       " 'helaas',\n",
       " 'explosion',\n",
       " 'goiing',\n",
       " 'hashphpopup',\n",
       " 'consistently',\n",
       " 'emergency',\n",
       " 'hashphangrybirds',\n",
       " 'ie6',\n",
       " 'statesmanlinkph',\n",
       " 'ipadlaptop',\n",
       " 'theater',\n",
       " 'storethe',\n",
       " 'hashphgrrr',\n",
       " 'controlling',\n",
       " 'exceeds',\n",
       " 'gsdmgoogle',\n",
       " 'designer',\n",
       " 'partay',\n",
       " 'planted',\n",
       " 'corporate',\n",
       " 'jquery',\n",
       " 'umbrella',\n",
       " 'hashphmiketyson',\n",
       " 'skiing',\n",
       " 'audi',\n",
       " 'heywire',\n",
       " 'noticing',\n",
       " '48',\n",
       " 'rwwtof6bcet',\n",
       " 'salicornia',\n",
       " 'heavyweight',\n",
       " '2100',\n",
       " '128',\n",
       " 'texaswith',\n",
       " 'american',\n",
       " 'moly',\n",
       " 'rel',\n",
       " 'exchief',\n",
       " 'loosing',\n",
       " 'carlson',\n",
       " 'hashphwam',\n",
       " 'affiliated',\n",
       " 'schedorg',\n",
       " 'hashphthankyoueconomy',\n",
       " 'glasser',\n",
       " 'googlelinkphpetition',\n",
       " 'hashphogilvy',\n",
       " 'tabletoptimized',\n",
       " 'novelty',\n",
       " 'hashphtoyjoybuy',\n",
       " 'deliver',\n",
       " 'effectively',\n",
       " 'importance',\n",
       " 'remake',\n",
       " 'shakedown',\n",
       " 'circular',\n",
       " 'dd',\n",
       " 'hashpheurorscg',\n",
       " 'multiplicity',\n",
       " 'effen',\n",
       " 'renewing',\n",
       " 'c9',\n",
       " 'congo',\n",
       " 'techstars',\n",
       " 'hashphqagbû',\n",
       " '12bn',\n",
       " 'hashphmayer',\n",
       " 'wwwadloopzlinkph',\n",
       " 'popupåêstore',\n",
       " 'grrrr',\n",
       " 'irl',\n",
       " 'gate',\n",
       " 'hashphaol',\n",
       " 'dinosaur',\n",
       " 'jqueryhtml5',\n",
       " 'ughhhapple',\n",
       " 'factory',\n",
       " 'fortuitous',\n",
       " 'hashphinpdx',\n",
       " 'hashphdigitalluxury',\n",
       " 'sprout',\n",
       " 'hashph120',\n",
       " '5min',\n",
       " 'interviewing',\n",
       " 'sxswhashphsxsw',\n",
       " 'innacurate',\n",
       " 'pensei',\n",
       " 'ûïlike',\n",
       " 'tinyurllinkph6gjmypj',\n",
       " 'hashphhbs',\n",
       " 'siliconvalley',\n",
       " 'shuffleboard',\n",
       " 'azure',\n",
       " 'c40',\n",
       " 'address',\n",
       " 'hashph1',\n",
       " 'summary',\n",
       " 'perma',\n",
       " 'i17',\n",
       " 'hashplinkphmerce',\n",
       " 'hashph4hb',\n",
       " 'everyonelinkphing',\n",
       " 'pointlow',\n",
       " 'blinkphinglinkphpetitors',\n",
       " '99cent',\n",
       " 'hashphkillerhack',\n",
       " 'sapete',\n",
       " 'hashphpodcasters',\n",
       " 'hashphwepartyhere',\n",
       " 'ipadcell',\n",
       " 'difficult',\n",
       " 'funnel',\n",
       " 'transdevice',\n",
       " 'twitterstream',\n",
       " '5124578800',\n",
       " 'demolition',\n",
       " 'hashphewww',\n",
       " 'chelsea',\n",
       " 'attendence',\n",
       " 'evry',\n",
       " 'lykwxhpyterh',\n",
       " 'pengen',\n",
       " 'hashphsxswbigbrands',\n",
       " 'restaurantsrating',\n",
       " 'entering',\n",
       " 'college',\n",
       " 'hashphdocumentally',\n",
       " 'trustworhy',\n",
       " 'atlantic',\n",
       " 'homie',\n",
       " 'remix',\n",
       " 'radius',\n",
       " 'notlinkphpatible',\n",
       " 'scheen',\n",
       " 'hashphlaptop',\n",
       " 'postfacebook',\n",
       " 'hashphloveit',\n",
       " 'distance',\n",
       " '4chans',\n",
       " 'gtfs',\n",
       " 'wbeing',\n",
       " 'huuray',\n",
       " '23track',\n",
       " 'importphant',\n",
       " 'wikitude',\n",
       " 'instrumental',\n",
       " 'foreshadowing',\n",
       " 'hashphveriphone',\n",
       " 'rail',\n",
       " 'omar',\n",
       " 'hashphecho_nest',\n",
       " 'hashphpickmeupanipad2',\n",
       " 'hashphsxswmonster',\n",
       " 'hashphihearnetwork',\n",
       " 'chimp',\n",
       " '504',\n",
       " 'âä_çáîùã¾ûâãôûârtph',\n",
       " 'hashphliveshows',\n",
       " 'burnbq',\n",
       " 'terrific',\n",
       " 'askd',\n",
       " 'hashphblogger',\n",
       " 'nfcrfid',\n",
       " '615ab',\n",
       " 'hashphcsr',\n",
       " 'whispergram',\n",
       " 'tt66h9tjn4ye',\n",
       " 'hatched',\n",
       " 'hashphjunkies',\n",
       " 'brunch',\n",
       " 'soft',\n",
       " 'happens',\n",
       " 'fitting',\n",
       " 'tokyo',\n",
       " 'journalist',\n",
       " 'hashplinkphments',\n",
       " 'appsand',\n",
       " 'rimhp',\n",
       " 'tom',\n",
       " 'hashphcrowley',\n",
       " 'hoodie',\n",
       " 'milk',\n",
       " 'ningun',\n",
       " 'amex',\n",
       " 'hashphallshare',\n",
       " 'hashphlatam',\n",
       " 'pinball',\n",
       " 'onsite',\n",
       " 'lowest',\n",
       " 'hashphipaddesignheadaches',\n",
       " 'behaviour',\n",
       " '2x',\n",
       " 'z9',\n",
       " 'visited',\n",
       " 'area',\n",
       " 'dried',\n",
       " 'todaylinkph',\n",
       " 'pst',\n",
       " 'interest',\n",
       " 'truelinkphpetitor',\n",
       " 'chair',\n",
       " 'shhh',\n",
       " '54',\n",
       " 'contraption',\n",
       " 'transit',\n",
       " 'annoying',\n",
       " 'hashphpc',\n",
       " 'hashphpsfk',\n",
       " 'ceopres',\n",
       " 'whiteboard',\n",
       " 'growth',\n",
       " 'txt',\n",
       " 'hashphdiversity',\n",
       " 'nast',\n",
       " '14th',\n",
       " 'intuitweve',\n",
       " '319',\n",
       " 'delicious',\n",
       " 'accidentally',\n",
       " 'bbc',\n",
       " 'volt',\n",
       " 'yorkers',\n",
       " 'acludont',\n",
       " 'hashphcontextclues',\n",
       " 'nonmacipad',\n",
       " 'hashphverizonftw',\n",
       " 'hashphsorry',\n",
       " 'headsup',\n",
       " 'eyeing',\n",
       " 'p7e9eme7kylj',\n",
       " 'curse',\n",
       " 'downstairs',\n",
       " 'firewall',\n",
       " 'lanyard',\n",
       " 'lonelyboy15',\n",
       " 'waaaambulance',\n",
       " 'patio',\n",
       " 'ep',\n",
       " 'onslaught',\n",
       " 'david',\n",
       " 'misdirection',\n",
       " 'chartph',\n",
       " 'powerpad',\n",
       " 'hashphtaplynx',\n",
       " 'hoodies',\n",
       " 'hashphillmakeitwork',\n",
       " 'adloopz',\n",
       " 'pubsubhubbub',\n",
       " 'waffling',\n",
       " 'hashphdigitalblasphemy',\n",
       " 'shuffle',\n",
       " 'sez',\n",
       " 'large',\n",
       " 'byû',\n",
       " 'hashphup',\n",
       " 'opportunism',\n",
       " 'republish',\n",
       " 'hashphclient',\n",
       " 'fullsteam',\n",
       " 'mdw',\n",
       " 'zlf',\n",
       " 'suggestionskind',\n",
       " 'hashphcrazy',\n",
       " 'monetization',\n",
       " 'dmi',\n",
       " 'hashpheatshopaustinapp',\n",
       " 'complex',\n",
       " 'hashphskrugsxsw',\n",
       " 'blonde',\n",
       " 'hashphguardian',\n",
       " 'scott',\n",
       " '285',\n",
       " 'season',\n",
       " 'lifespan',\n",
       " 'spanishspeaking',\n",
       " 'hashphfuckit',\n",
       " 'alice',\n",
       " 'hashphwellplayed',\n",
       " 'unprepared',\n",
       " 'enthusiast',\n",
       " 'geekdouche',\n",
       " 'pit',\n",
       " 'departure',\n",
       " 'livetweets',\n",
       " 'hashphveryslow',\n",
       " 'exp',\n",
       " 'ona',\n",
       " 'tipping',\n",
       " 'hashphpushsnowboarding',\n",
       " 'hashphyam',\n",
       " 'hashphdenniscrowley',\n",
       " 'timechange',\n",
       " 'charlie',\n",
       " 'hashphpartylikeits1986',\n",
       " 'facial',\n",
       " 'relinquish',\n",
       " 'hitchery',\n",
       " 'dongle',\n",
       " 'franken',\n",
       " '317',\n",
       " 'autograph',\n",
       " 'hashphanalog',\n",
       " 'wsweet',\n",
       " 'tlinkph',\n",
       " 'hardcore',\n",
       " 'hashphprlinkphmerce',\n",
       " 'hashphtakeonefortheteam',\n",
       " 'andro',\n",
       " 'computer',\n",
       " 'åè',\n",
       " 'googlezation',\n",
       " 'smentisce',\n",
       " 'optimal',\n",
       " 'smell',\n",
       " 'cw',\n",
       " 'grilled',\n",
       " 'safe',\n",
       " 'leader',\n",
       " 'menphlinkphe',\n",
       " 'starring',\n",
       " 'frame',\n",
       " 'handhashphsxsw',\n",
       " 'ec2',\n",
       " 'founded',\n",
       " 'figured',\n",
       " 'iphonetoting',\n",
       " 'frying',\n",
       " 'hashphnerdking',\n",
       " 'bursting',\n",
       " 'amen',\n",
       " 'rewardstype',\n",
       " 'correcting',\n",
       " 'googlers',\n",
       " 'potentially',\n",
       " 'textbook',\n",
       " '4chan4eva',\n",
       " 'melody',\n",
       " 'thier',\n",
       " 'hashphgofigure',\n",
       " 'hashphallinkphfortfooddiet',\n",
       " 'hashphcheckin',\n",
       " 'obnoxiously',\n",
       " '7580',\n",
       " 'existential',\n",
       " 'tie',\n",
       " 'industrial',\n",
       " 'hashphwthû',\n",
       " 'hero',\n",
       " 'syd',\n",
       " 'forth',\n",
       " 'discoveryû',\n",
       " 'hashphjzsxsw',\n",
       " 'believing',\n",
       " 'springing',\n",
       " 'fedora',\n",
       " 'fundamental',\n",
       " 'engineering',\n",
       " 'lifter',\n",
       " 'russian',\n",
       " '4sqwill',\n",
       " 'thinkhashphagileagency',\n",
       " '1100',\n",
       " 'nook',\n",
       " 'bait',\n",
       " 'exact',\n",
       " 'outagree',\n",
       " 'weeknd',\n",
       " 'hashphflashmob',\n",
       " 'friendly',\n",
       " 'hashphinspiredbyprint',\n",
       " 'hashphsocialnetwork',\n",
       " 'hashphlbseverywhere',\n",
       " '150mmlinkphe',\n",
       " 'brown',\n",
       " 'hashphhotsheet',\n",
       " 'apply',\n",
       " 'hashphblogging',\n",
       " 'tease',\n",
       " 'abound',\n",
       " 'z7',\n",
       " 'hashphie',\n",
       " 'cierto',\n",
       " 'llc',\n",
       " 'hashphwack',\n",
       " 'amys',\n",
       " 'antisocial',\n",
       " 'sxswlinkphinteractivelive',\n",
       " 'hashphtruestory',\n",
       " 'annuncia',\n",
       " 'interestingrtph',\n",
       " 'posbly',\n",
       " 'neck',\n",
       " 'hashphpeace',\n",
       " 'acerbic',\n",
       " 'patient',\n",
       " 'spotify',\n",
       " 'halftone',\n",
       " 'dad',\n",
       " 'googlesavvy',\n",
       " 'adapter',\n",
       " 'mini',\n",
       " 'snack',\n",
       " 'hashphwhowillrise',\n",
       " 'mayertaking',\n",
       " 'encourages',\n",
       " 'hashphsxsma',\n",
       " 'seatmate',\n",
       " 'incapable',\n",
       " 'blackout',\n",
       " 'hashphcrashing',\n",
       " 'hashphstartup',\n",
       " 'thisisdare',\n",
       " 'wey',\n",
       " 'readingû',\n",
       " 'burner',\n",
       " 'alumnus',\n",
       " 'plucked',\n",
       " 'aaron',\n",
       " 'spied',\n",
       " 'losing',\n",
       " 'donkey',\n",
       " 'contextrlinkphmendations',\n",
       " 'warp',\n",
       " 'hashphuifail',\n",
       " 'joining',\n",
       " 'gamesalad',\n",
       " 'wpacific',\n",
       " 'sole',\n",
       " 'hashphsocialnews',\n",
       " 'rollin',\n",
       " 'gd',\n",
       " 'fourth',\n",
       " 'affect',\n",
       " 'critically',\n",
       " 'boarding',\n",
       " 'muffin',\n",
       " 'hashphapraxia',\n",
       " 'hashphsrsly',\n",
       " 'yea',\n",
       " 'hashphsxswinfo',\n",
       " 'suicidal',\n",
       " 'notetaking',\n",
       " 'suffer',\n",
       " 'hereûªs',\n",
       " 'concrete',\n",
       " 'hacking',\n",
       " 'storei',\n",
       " 'rounded',\n",
       " 'glowinthedark',\n",
       " 'brandnew',\n",
       " 'unveil',\n",
       " 'autocorrect',\n",
       " 'deleting',\n",
       " 'looong',\n",
       " 'gran',\n",
       " 'cab',\n",
       " 'discoverable',\n",
       " 'ure',\n",
       " 'alinkphplish',\n",
       " 'sosososo',\n",
       " 'pictionary',\n",
       " 'rabid',\n",
       " 'hashphhcinno',\n",
       " 'honestly',\n",
       " 'hardware',\n",
       " 'evil',\n",
       " 'hashphgaryvee',\n",
       " 'ispyart',\n",
       " 'hate',\n",
       " 'ipd',\n",
       " 'scrub',\n",
       " '2b',\n",
       " 'hashphinagist',\n",
       " 'removeburn',\n",
       " 'cache',\n",
       " 'hashphbeer',\n",
       " 'mustache',\n",
       " 'clipboard',\n",
       " 'texttospeech',\n",
       " 'proceeds',\n",
       " 'hashphappleapple',\n",
       " 'thingamajig',\n",
       " 'partial',\n",
       " 'prez',\n",
       " 'netscape',\n",
       " 'worst',\n",
       " 'hashphbillmurray',\n",
       " 'cinemagoers',\n",
       " 'mascot',\n",
       " 'classiest',\n",
       " 'donate',\n",
       " 'arelinkphing',\n",
       " 'spill',\n",
       " 'unfortunate',\n",
       " 'swoop',\n",
       " 'menphw',\n",
       " 'hashphswswi',\n",
       " 'warner',\n",
       " 'smallest',\n",
       " 'hashphbandcamp',\n",
       " 'hooker',\n",
       " 'screw',\n",
       " 'hashphnewtwitter',\n",
       " 'lakers',\n",
       " 'trueûïmenph',\n",
       " 'forgotten',\n",
       " 'macys',\n",
       " 'hashphhhrs',\n",
       " 'irrelevant',\n",
       " 'spontaniety',\n",
       " 'hashphlightnessofbeing',\n",
       " 'pattern',\n",
       " 'hashphrandomactofkindness',\n",
       " 'stacked',\n",
       " 'hashphsocialviewing',\n",
       " 'magical',\n",
       " 'asst',\n",
       " 'nonhashphsxsw',\n",
       " 'begun',\n",
       " 'ûïcoming',\n",
       " 'brick',\n",
       " 'coolgoofy',\n",
       " 'shea',\n",
       " 'messed',\n",
       " 'shpeal',\n",
       " 'hashphbillboard',\n",
       " 'void',\n",
       " 'ahold',\n",
       " 'budget',\n",
       " 'frankeninterface',\n",
       " 'c43',\n",
       " 'repair',\n",
       " 'sayin',\n",
       " 'hashphdigisxsw',\n",
       " 'hashphmobilephotography',\n",
       " 'congress6th',\n",
       " 'ballroomd',\n",
       " 'tg',\n",
       " 'crazybrilliantconvenient',\n",
       " 'kanyes',\n",
       " 'microsofts',\n",
       " 'rapid',\n",
       " 'elevator',\n",
       " 'chunk',\n",
       " 'qandroid',\n",
       " 'submit',\n",
       " 'hashphshice',\n",
       " 'swapping',\n",
       " 'packard',\n",
       " 'wifionly',\n",
       " 'riff',\n",
       " 'hashphscinfluence',\n",
       " 'nowûòand',\n",
       " 'uncatalogued',\n",
       " 'gummy',\n",
       " 'hashphwakenbake',\n",
       " 'viewsday',\n",
       " 'n2',\n",
       " 'z17',\n",
       " 'budge',\n",
       " 'eventful',\n",
       " 'integrates',\n",
       " 'crushing',\n",
       " 'organised',\n",
       " 'slaughter',\n",
       " 'fake',\n",
       " 'vacuous',\n",
       " 'festivity',\n",
       " 'fairy',\n",
       " 'and',\n",
       " 'ios5',\n",
       " 'crush',\n",
       " 'skiiers',\n",
       " 'busted',\n",
       " 'stevecase',\n",
       " 'magically',\n",
       " 'drinking',\n",
       " 'amoral',\n",
       " 'disaster',\n",
       " 'nolinkphment',\n",
       " 'customized',\n",
       " 'mighty',\n",
       " 'metaphor',\n",
       " 'experimentation',\n",
       " 'knob',\n",
       " 'hashphsgrocks',\n",
       " 'topping',\n",
       " 'lavaca',\n",
       " 'hashphsxswinfluence',\n",
       " 'hashphitouru',\n",
       " 'beating',\n",
       " 'wicked',\n",
       " 'tummy',\n",
       " 'hashphworklifeprogress',\n",
       " 'hashphnotmycollegesxsw',\n",
       " 'hashpha11y2go',\n",
       " 'hashphliquidux',\n",
       " 'bateman',\n",
       " 'hashphdarknet',\n",
       " 'hashphsamsunggalaxys',\n",
       " '86',\n",
       " 'h4ackers',\n",
       " 'hashphyouareinteractive',\n",
       " 'whirlwind',\n",
       " 'intentionsnow',\n",
       " 'para',\n",
       " 'lived',\n",
       " 'human',\n",
       " 'radisson',\n",
       " 'n33',\n",
       " 'selfserve',\n",
       " 'quoted',\n",
       " 'blanc',\n",
       " 'hashphsmile',\n",
       " 'quoi',\n",
       " 'grrrplancast',\n",
       " 'andriod',\n",
       " 'dotremendous',\n",
       " 'shoutout',\n",
       " 'foam',\n",
       " 'mint',\n",
       " 'menphc',\n",
       " 'dime',\n",
       " 'rey',\n",
       " 'wedmon',\n",
       " 'lick',\n",
       " 'bee',\n",
       " 'recorded',\n",
       " 'anû',\n",
       " 'informed',\n",
       " 'marketshare',\n",
       " 'disliking',\n",
       " 'ragtubelinkph',\n",
       " 'health',\n",
       " 'reassemble',\n",
       " 'sharegather',\n",
       " 'ritas',\n",
       " 'hashphusa',\n",
       " 'jdnya',\n",
       " 'hashphphilanthropy',\n",
       " '316',\n",
       " 'gapminder',\n",
       " 'tug',\n",
       " 'cloudapp',\n",
       " 'predicting',\n",
       " 'hashphsmaroi',\n",
       " '350',\n",
       " 'landed',\n",
       " 'corralling',\n",
       " 'panelinteresting',\n",
       " 'hardly',\n",
       " 'hashphkids',\n",
       " 'regularlyscheduled',\n",
       " '9abc',\n",
       " 'scheme',\n",
       " 'hashphletsdothis',\n",
       " 'noniphone',\n",
       " 'hashphnpac',\n",
       " 'lengthy',\n",
       " 'hashphbrand',\n",
       " '829',\n",
       " 'ramping',\n",
       " 'envisions',\n",
       " 'fixedfind',\n",
       " 'cartoonishly',\n",
       " 'relevanceannounced',\n",
       " '710',\n",
       " 'punishment',\n",
       " 'collaboration',\n",
       " 'hashphmsusxsw',\n",
       " 'tending',\n",
       " 'bah',\n",
       " '1100am',\n",
       " '7th',\n",
       " 'hashphrejection',\n",
       " 'hashphfilmfestepic',\n",
       " 'blogpost',\n",
       " 'margin',\n",
       " 'sexier',\n",
       " 'bridge',\n",
       " 'hashphoffers',\n",
       " 'hashphfastball',\n",
       " 'contrary',\n",
       " 'multicolor',\n",
       " ...}"
      ]
     },
     "execution_count": 890,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neut_neg_token_list_unique2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Testing other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "nlp = English()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       @jessedee Know about @fludapp ? Awesome iPad/i...\n",
       "2       @swonderlin Can not wait for #iPad 2 also. The...\n",
       "4       @sxtxstate great stuff on Fri #SXSW: Marissa M...\n",
       "7       #SXSW is just starting, #CTIA is around the co...\n",
       "8       Beautifully smart and simple idea RT @madebyma...\n",
       "                              ...                        \n",
       "9072    @mention your iPhone 4 cases are Rad and Ready...\n",
       "9077    @mention your PR guy just convinced me to swit...\n",
       "9079    &quot;papyrus...sort of like the ipad&quot; - ...\n",
       "9085    I've always used Camera+ for my iPhone b/c it ...\n",
       "9088                        Ipad everywhere. #SXSW {link}\n",
       "Name: tweet_text, Length: 2978, dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_tweet_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(96,)\n",
      "[ 1.5080006   0.20474844  0.5546193  -0.90579414 -0.54141414 -0.9824686\n",
      "  0.5253784  -1.4117908  -0.8251685  -0.15485895  0.55209285  0.7007918\n",
      "  0.48446506  0.34851265  0.19821697  0.6071049   0.92223513 -0.8365748\n",
      " -0.07147411  0.5213211  -0.45954704  0.73926437 -0.8330599   0.32836628\n",
      " -0.00541195  0.10246983 -0.28939652 -0.32321608 -0.07963422 -0.0561545\n",
      " -1.2349129  -0.5410965  -0.23048031 -0.9607055   0.59256613  0.54079735\n",
      " -1.8728933  -0.00399333 -0.06148595  0.6371069  -0.05743659 -0.6361483\n",
      " -0.80609286  1.0348423   0.2242944  -0.23417483  0.29439375 -0.35090202\n",
      "  0.19317758 -0.3185281   0.51226294  1.1309446  -0.41559738  0.15457207\n",
      "  1.6295617  -1.2565141   0.20126943  0.01892669  1.7639434   0.4675427\n",
      " -0.15381673 -0.40200907 -0.2869364  -0.19344324 -0.68605137  0.00293952\n",
      " -0.21419257 -0.29355788 -0.3246354  -0.36205465  1.5996232  -0.6480825\n",
      "  0.4077111  -0.5152909  -0.64171624  0.29932743 -1.3886542  -0.5850692\n",
      " -0.10415816  1.2317246   0.77090836 -0.73733115  0.41132918 -0.18870486\n",
      " -1.0053046   0.23512203 -0.28804928 -0.02900743  0.16250658 -0.3472693\n",
      " -0.7139532   1.2781031   0.71377337 -0.9716526  -0.28996092  0.45971975]\n"
     ]
    }
   ],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "sxsw = nlp('sxsw')\n",
    "print(sxsw.vector.shape)\n",
    "print(sxsw.vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".@wesley83 I have a 3G iPhone. After 3 hrs tweeting at #RISE_Austin, it was dead!  I need to upgrade. Plugin stations at #SXSW.\n",
      "@jessedee Know about @fludapp ? Awesome iPad/iPhone app that you'll likely appreciate for its design. Also, they're giving free Ts at #SXSW\n",
      "@swonderlin Can not wait for #iPad 2 also. They should sale them down at #SXSW.\n",
      "@sxsw I hope this year's festival isn't as crashy as this year's iPhone app. #sxsw\n",
      "@sxtxstate great stuff on Fri #SXSW: Marissa Mayer (Google), Tim O'Reilly (tech books/conferences) &amp; Matt Mullenweg (Wordpress)\n"
     ]
    }
   ],
   "source": [
    "for tweet in df['tweet_text'][:5]:\n",
    "    print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-253-cbe196294dfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mterms_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mterm\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mterm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tweet_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Update the counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcount_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mterms_all\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# Print the first 5 most frequent words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    620\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fast path when counter is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "count_all = Counter()\n",
    "for tweet in df['tweet_text']:\n",
    "    # Create a list with all the terms\n",
    "    terms_all = [term for term in df['tweet_text']]\n",
    "    # Update the counter\n",
    "    count_all.update(terms_all)\n",
    "# Print the first 5 most frequent words\n",
    "print(count_all.most_common(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "#hashtags\n",
    "# Count terms only once, equivalent to Document Frequency\n",
    "terms_single = set(terms_all)\n",
    "# Count hashtags only\n",
    "terms_hash = [term for term in preprocess(tweet['text']) \n",
    "              if term.startswith('#')]\n",
    "# Count terms only (no hashtags, no mentions)\n",
    "terms_only = [term for term in preprocess(tweet['text']) \n",
    "              if term not in stop and\n",
    "              not term.startswith(('#', '@'))] \n",
    "              # mind the ((double brackets))\n",
    "              # startswith() takes a tuple (not a list) if \n",
    "              # we pass a list of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
